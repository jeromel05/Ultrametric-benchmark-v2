#!/bin/sh
#SBATCH --account=theory
#SBATCH -c 4
#SBATCH --time=11:55:00
#SBATCH --gres gpu:1
#SBATCH --mail-type=FAIL
#SBATCH --mail-user=jl6181@columbia.edu
#SBATCH --error="/burg/home/jl6181/home/scratch/stderr/%j_err.out"
#SBATCH --output="/burg/home/jl6181/home/scratch/%j.out"

module load cuda11.0/toolkit/11.0.3 cuda11.0/blas/11.0.3 cudnn8.0-cuda11.0/8.0.5.39

echo "JOB_ID"
echo $SLURM_JOB_ID
start=`date +%s`

while getopts h:b:d:l:s:e:f:a:g: flag
do
    case "${flag}" in
        h) h_size=${OPTARG};;
        b) b_len=${OPTARG};;
        d) tree_depth=${OPTARG};;
        l) lr=${OPTARG};;
        s) start_seed=${OPTARG};;
        e) eval_freq=${OPTARG};;
	f) ef_factor=${OPTARG};;
        a) start_step=${OPTARG};;
        g) mode=${OPTARG};;
    esac
done

echo "RUNNING UM MNIST: HID_SIZE $h_size B_LEN $b_len LR $lr SEED $start_seed EF $eval_freq EF_F $ef_factor MODE $mode"
python ~/home/repo/code/src/run.py --datafolder ~/home/repo/data --logfolder /burg/home/jl6181/home/scratch/logs/ --gpu 1 --dataset mnist --batch_size_train 2 --batch_size_test 1000 --max_epochs 10000 --nb_folds 1 --num_workers 4 --mode $mode --b_len $b_len --eval_freq $eval_freq --hidden_size $h_size --lr $lr --early_stop --job_id $SLURM_JOB_ID --start_seed $start_seed --eval_freq_factor $ef_factor --last_val_step $start_step

end=`date +%s`
runtime=$((end-start))
echo "JOB COMPLETED IN $runtime"
